{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Морфология 1\n",
    "\n",
    "Здесь мы познакомимся с двумя мофрологическими анализоторами: pymorphy и mystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = u'Гло́кая ку́здра ште́ко будлану́ла бо́кра и курдя́чит бокрёнка'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. MyStem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymystem3\n",
      "  Downloading https://files.pythonhosted.org/packages/00/8c/98b43c5822620458704e187a1666616c1e21a846ede8ffda493aabe11207/pymystem3-0.2.0-py3-none-any.whl\n",
      "Collecting requests (from pymystem3)\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "  Downloading https://files.pythonhosted.org/packages/51/bd/23c926cd341ea6b7dd0b2a00aba99ae0f828be89d72b2190f27c11d4b7fb/requests-2.22.0-py2.py3-none-any.whl (57kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 1.2MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 (from requests->pymystem3)\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "  Downloading https://files.pythonhosted.org/packages/e0/da/55f51ea951e1b7c63a579c09dd7db825bb730ec1fe9c0180fc77bfb31448/urllib3-1.25.6-py2.py3-none-any.whl (125kB)\n",
      "\u001b[K    100% |████████████████████████████████| 133kB 981kB/s ta 0:00:01\n",
      "\u001b[?25hCollecting certifi>=2017.4.17 (from requests->pymystem3)\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "  Downloading https://files.pythonhosted.org/packages/18/b0/8146a4f8dd402f60744fa380bc73ca47303cccf8b9190fd16a827281eac2/certifi-2019.9.11-py2.py3-none-any.whl (154kB)\n",
      "\u001b[K    100% |████████████████████████████████| 163kB 2.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting chardet<3.1.0,>=3.0.2 (from requests->pymystem3)\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "  Using cached https://files.pythonhosted.org/packages/bc/a9/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8/chardet-3.0.4-py2.py3-none-any.whl\n",
      "Collecting idna<2.9,>=2.5 (from requests->pymystem3)\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "\u001b[33m  Cache entry deserialization failed, entry ignored\u001b[0m\n",
      "  Downloading https://files.pythonhosted.org/packages/14/2c/cd551d81dbe15200be1cf41cd03869a46fe7226e7450af7a6545bfc474c9/idna-2.8-py2.py3-none-any.whl (58kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 1.2MB/s ta 0:00:011\n",
      "\u001b[?25hInstalling collected packages: urllib3, certifi, chardet, idna, requests, pymystem3\n",
      "Successfully installed certifi-2019.9.11 chardet-3.0.4 idna-2.8 pymystem3-0.2.0 requests-2.22.0 urllib3-1.25.6\n"
     ]
    }
   ],
   "source": [
    "# поставим модуль если он еще не стоит\n",
    "!pip install pymystem3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing mystem to /home/egorov/.local/bin/mystem from http://download.cdn.yandex.net/mystem/mystem-3.1-linux-64bit.tar.gz\n"
     ]
    }
   ],
   "source": [
    "from pymystem3 import Mystem\n",
    "# инициализация собственно инициализатора\n",
    "mystem_analyzer = Mystem(entire_input=False, disambiguation=False)\n",
    "# entire_output - сохранение всего входа (напр. пробелов)\n",
    "# disambiguation - снятие омонимии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Две основные функции Mystem:\n",
    "- Проводить мофрологический анализ\n",
    "- Приводить начальные формы для слов в тексте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystem_result = mystem_analyzer.analyze(sample_text)\n",
    "mystem_lemmas = mystem_analyzer.lemmatize(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Гло́кая ку́здра ште́ко будлану́ла бо́кра и курдя́чит бокрёнка\n",
      "глокая\n",
      "куздра\n",
      "штеко\n",
      "будлануть\n",
      "бокра\n",
      "и\n",
      "курдячить\n",
      "бокренка\n"
     ]
    }
   ],
   "source": [
    "# Посмотрим, что у нас получилось при лемматизации \n",
    "# (да, чтобы вывести юникодные строки на втором питоне приходится так извращаться)\n",
    "print (sample_text)\n",
    "for word in mystem_lemmas:    \n",
    "    print (word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Гло́кая\n",
      "\t {'lex': 'глокая', 'wt': 0.3605448292, 'qual': 'bastard', 'gr': 'S,ед,жен,неод=им'}\n",
      "\t {'lex': 'глокать', 'wt': 0.3605448292, 'qual': 'bastard', 'gr': 'V,несов=непрош,деепр,пе'}\n",
      "\t {'lex': 'глокая', 'wt': 0.1038369108, 'qual': 'bastard', 'gr': 'S,жен,од=им,ед'}\n",
      "\t {'lex': 'глокай', 'wt': 0.09304979929, 'qual': 'bastard', 'gr': 'S,муж,неод=род,ед'}\n",
      "\t {'lex': 'глокать', 'wt': 0.03306575604, 'qual': 'bastard', 'gr': 'V,несов,нп=непрош,деепр'}\n",
      "\t {'lex': 'глокий', 'wt': 0.01624943977, 'qual': 'bastard', 'gr': 'A=им,ед,полн,жен'}\n",
      "\t {'lex': 'глокать', 'wt': 0.01512198266, 'qual': 'bastard', 'gr': 'V,несов,пе=непрош,деепр'}\n",
      "\t {'lex': 'глокий', 'wt': 0.01077529943, 'qual': 'bastard', 'gr': 'A=им,ед,полн,жен'}\n",
      "\t {'lex': 'глокать', 'wt': 0.006811153662, 'qual': 'bastard', 'gr': 'V,нп=непрош,деепр,несов'}\n",
      "ку́здра\n",
      "\t {'lex': 'куздра', 'wt': 0.6292693823, 'qual': 'bastard', 'gr': 'S,ед,жен,неод=им'}\n",
      "\t {'lex': 'куздра', 'wt': 0.3707306177, 'qual': 'bastard', 'gr': 'S,гео,жен,неод=им,ед'}\n",
      "ште́ко\n",
      "\t {'lex': 'штеко', 'wt': 0.3217673592, 'qual': 'bastard', 'gr': 'S,имя,мж,од=(пр,мн|пр,ед|вин,мн|вин,ед|дат,мн|дат,ед|род,мн|род,ед|твор,мн|твор,ед|им,мн|им,ед)'}\n",
      "\t {'lex': 'штеко', 'wt': 0.2574119755, 'qual': 'bastard', 'gr': 'ADV='}\n",
      "\t {'lex': 'штеко', 'wt': 0.1608460987, 'qual': 'bastard', 'gr': 'S,сред,неод=(пр,мн|пр,ед|вин,мн|вин,ед|дат,мн|дат,ед|род,мн|род,ед|твор,мн|твор,ед|им,мн|им,ед)'}\n",
      "\t {'lex': 'штеко', 'wt': 0.08253134141, 'qual': 'bastard', 'gr': 'S,сред,неод=(вин,ед|им,ед)'}\n",
      "\t {'lex': 'штеко', 'wt': 0.07936870775, 'qual': 'bastard', 'gr': 'S,ед,сред,неод=(вин|им)'}\n",
      "\t {'lex': 'штеко', 'wt': 0.03215211714, 'qual': 'bastard', 'gr': 'S,имя,муж,од=(пр,мн|пр,ед|вин,мн|вин,ед|дат,мн|дат,ед|род,мн|род,ед|твор,мн|твор,ед|им,мн|им,ед)'}\n",
      "\t {'lex': 'штеко', 'wt': 0.03210293606, 'qual': 'bastard', 'gr': 'S,фам,мж,од=(пр,мн|пр,ед|вин,мн|вин,ед|дат,мн|дат,ед|род,мн|род,ед|твор,мн|твор,ед|им,мн|им,ед)'}\n",
      "\t {'lex': 'штеко', 'wt': 0.03208609722, 'qual': 'bastard', 'gr': 'S,гео,ед,муж,неод=(пр|вин|дат|род|твор|им)'}\n",
      "\t {'lex': 'штекий', 'wt': 0.001720046713, 'qual': 'bastard', 'gr': 'A=ед,кр,сред'}\n",
      "\t {'lex': 'штекий', 'wt': 1.332032949e-05, 'qual': 'bastard', 'gr': 'A=ед,кр,сред'}\n",
      "\t {'lex': 'штеко', 'wt': 0, 'qual': 'bastard', 'gr': 'S,имя,ед,муж,од=им'}\n",
      "будлану́ла\n",
      "\t {'lex': 'будлануть', 'wt': 0.2884335962, 'qual': 'bastard', 'gr': 'V,обсц,сов=прош,ед,изъяв,жен'}\n",
      "\t {'lex': 'будлануть', 'wt': 0.2884335962, 'qual': 'bastard', 'gr': 'V,разг,обсц,сов=прош,ед,изъяв,жен'}\n",
      "\t {'lex': 'будланула', 'wt': 0.09985378522, 'qual': 'bastard', 'gr': 'S,имя,жен,од=им,ед'}\n",
      "\t {'lex': 'будлануть', 'wt': 0.05695153583, 'qual': 'bastard', 'gr': 'V,сов,пе=прош,ед,изъяв,жен'}\n",
      "\t {'lex': 'будлануть', 'wt': 0.05212627477, 'qual': 'bastard', 'gr': 'V,сов,пе=прош,ед,изъяв,жен'}\n",
      "\t {'lex': 'будлануть', 'wt': 0.04770114448, 'qual': 'bastard', 'gr': 'V,сов,нп=прош,ед,изъяв,жен'}\n",
      "\t {'lex': 'будлануть', 'wt': 0.04683850382, 'qual': 'bastard', 'gr': 'V,сов,пе=прош,ед,изъяв,жен'}\n",
      "\t {'lex': 'будланула', 'wt': 0.04299689435, 'qual': 'bastard', 'gr': 'S,жен,неод=им,ед'}\n",
      "\t {'lex': 'будланул', 'wt': 0.03753661836, 'qual': 'bastard', 'gr': 'S,муж,од=(вин,ед|род,ед)'}\n",
      "\t {'lex': 'будлануть', 'wt': 0.02766311711, 'qual': 'bastard', 'gr': 'V,сов,нп=прош,ед,изъяв,жен'}\n",
      "\t {'lex': 'будланывать', 'wt': 0.01146493374, 'qual': 'bastard', 'gr': 'V,пе=прош,ед,изъяв,жен,сов'}\n",
      "бо́кра\n",
      "\t {'lex': 'бокра', 'wt': 0.8898982327, 'qual': 'bastard', 'gr': 'S,ед,жен,неод=им'}\n",
      "\t {'lex': 'бокрый', 'wt': 0.1101017673, 'qual': 'bastard', 'gr': 'A=ед,кр,жен'}\n",
      "и\n",
      "\t {'lex': 'и', 'wt': 0.9999770357, 'gr': 'CONJ='}\n",
      "\t {'lex': 'и', 'wt': 1.020511514e-05, 'gr': 'INTJ='}\n",
      "\t {'lex': 'и', 'wt': 6.379604644e-06, 'gr': 'S,сокр=(пр,мн|пр,ед|вин,мн|вин,ед|дат,мн|дат,ед|род,мн|род,ед|твор,мн|твор,ед|им,мн|им,ед)'}\n",
      "\t {'lex': 'и', 'wt': 6.37957056e-06, 'gr': 'PART='}\n",
      "курдя́чит\n",
      "\t {'lex': 'курдячить', 'wt': 0.5, 'qual': 'bastard', 'gr': 'V,обсц,сов,пе=непрош,ед,изъяв,3-л'}\n",
      "\t {'lex': 'курдячить', 'wt': 0.5, 'qual': 'bastard', 'gr': 'V,обсц,несов,пе=непрош,ед,изъяв,3-л'}\n",
      "бокрёнка\n",
      "\t {'lex': 'бокренка', 'wt': 0.2200160995, 'qual': 'bastard', 'gr': 'S,имя,жен,од=им,ед'}\n",
      "\t {'lex': 'бокренок', 'wt': 0.165166425, 'qual': 'bastard', 'gr': 'S,муж,неод=род,ед'}\n",
      "\t {'lex': 'бокренка', 'wt': 0.1392542771, 'qual': 'bastard', 'gr': 'S,жен,од=им,ед'}\n",
      "\t {'lex': 'бокренка', 'wt': 0.1240808471, 'qual': 'bastard', 'gr': 'S,жен,неод=им,ед'}\n",
      "\t {'lex': 'бокренок', 'wt': 0.1205990358, 'qual': 'bastard', 'gr': 'S,муж,неод=род,ед'}\n",
      "\t {'lex': 'бокренок', 'wt': 0.09129371203, 'qual': 'bastard', 'gr': 'S,муж,од=(вин,ед|род,ед)'}\n",
      "\t {'lex': 'бокренка', 'wt': 0.07074299558, 'qual': 'bastard', 'gr': 'S,имя,мж,од=им,ед'}\n",
      "\t {'lex': 'бокренк', 'wt': 0.06884660791, 'qual': 'bastard', 'gr': 'S,имя,муж,од=(вин,ед|род,ед)'}\n"
     ]
    }
   ],
   "source": [
    "# Ну и результат морфологического анализа\n",
    "# выведены всевозможные разборы, чтобы оценить масшатбы\n",
    "for word in mystem_result:\n",
    "    print (word['text'])\n",
    "    for res in word['analysis']:\n",
    "        print ('\\t', res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим теперь анализатор со снятием омонимии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystem_analyzer2 = Mystem(entire_input=False, disambiguation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystem_result2 = mystem_analyzer2.analyze(sample_text)\n",
    "mystem_lemmas2 = mystem_analyzer2.lemmatize(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Гло́кая ку́здра ште́ко будлану́ла бо́кра и курдя́чит бокрёнка\n",
      "глокая глокай\n",
      "куздра куздра\n",
      "штеко штеко\n",
      "будлануть будланул\n",
      "бокра бокра\n",
      "и и\n",
      "курдячить курдячить\n",
      "бокренка бокренок\n"
     ]
    }
   ],
   "source": [
    "print (sample_text)\n",
    "for (word, word2) in zip(mystem_lemmas, mystem_lemmas2):    \n",
    "    print (word, word2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Гло́кая\n",
      "\t {'lex': 'глокай', 'wt': 0.09304979929, 'qual': 'bastard', 'gr': 'S,муж,неод=род,ед'}\n",
      "ку́здра\n",
      "\t {'lex': 'куздра', 'wt': 0.6292693823, 'qual': 'bastard', 'gr': 'S,ед,жен,неод=им'}\n",
      "ште́ко\n",
      "\t {'lex': 'штеко', 'wt': 0.2574119755, 'qual': 'bastard', 'gr': 'ADV='}\n",
      "будлану́ла\n",
      "\t {'lex': 'будланул', 'wt': 0.03753661836, 'qual': 'bastard', 'gr': 'S,муж,од=(вин,ед|род,ед)'}\n",
      "бо́кра\n",
      "\t {'lex': 'бокра', 'wt': 0.8898982327, 'qual': 'bastard', 'gr': 'S,ед,жен,неод=им'}\n",
      "и\n",
      "\t {'lex': 'и', 'wt': 0.9999770357, 'gr': 'CONJ='}\n",
      "курдя́чит\n",
      "\t {'lex': 'курдячить', 'wt': 0.5, 'qual': 'bastard', 'gr': 'V,обсц,сов,пе=непрош,ед,изъяв,3-л'}\n",
      "бокрёнка\n",
      "\t {'lex': 'бокренок', 'wt': 0.165166425, 'qual': 'bastard', 'gr': 'S,муж,неод=род,ед'}\n"
     ]
    }
   ],
   "source": [
    "for word in mystem_result2:\n",
    "    print (word['text'])\n",
    "    for res in word['analysis']:\n",
    "        print ('\\t', res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проблемы MyStem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "александра\n",
      "иванов\n",
      "пойти\n",
      "в\n",
      "кино\n",
      "\n",
      "александра\n",
      "иванов\n",
      "видеть\n",
      "в\n",
      "кино\n",
      "с\n",
      "кто-то\n",
      "\n",
      "воробей\n",
      "сегодня\n",
      "вставать\n",
      "не\n",
      "с\n",
      "тот\n",
      "нога\n",
      "\n"
     ]
    }
   ],
   "source": [
    "disambiguations = [ 'Александра Иванова пошла в кино',\n",
    "                    'Александра Иванова видели в кино с кем-то',\n",
    "                    'Воробьев сегодня встал не с той ноги']\n",
    "\n",
    "disambiguation_results = []\n",
    "for dis in disambiguations:\n",
    "    disambiguation_results.append(mystem_analyzer2.lemmatize(dis))\n",
    "    \n",
    "for res in disambiguation_results:\n",
    "    for word in res:\n",
    "        print(word)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание\n",
    "Для того, чтобы наиграться с MyStem, предлагается написать методы, которые:\n",
    "- находит топ n лексем\n",
    "- находит слова с наибольшей и наименьшей энтропией"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "import math\n",
    "def get_top_words(text, n):\n",
    "    '''\n",
    "    :param text: input text in russian\n",
    "    :param n: number of most common words\n",
    "    :return: list of most common lexemas\n",
    "    '''\n",
    "    dictionary = {}\n",
    "    for word in text.split(' '):\n",
    "        if word not in dictionary:\n",
    "            dictionary[word] = 0\n",
    "        dictionary[word] += 1\n",
    "    sorted_dictionary = sorted(dictionary.items(), key=operator.itemgetter(1))[::-1]\n",
    "    answer = [x[0] for x in sorted_dictionary[:n]]\n",
    "    return answer\n",
    "\n",
    "def get_max_entropy_words(text, n):\n",
    "    '''\n",
    "    :param text: input text in russian\n",
    "    :param n: number of most words with maximun entropy\n",
    "    :return: list of words with entropies\n",
    "    '''\n",
    "    dictionary = {}\n",
    "    count_words = len(text.split(' '))\n",
    "    eps = 1e-7\n",
    "    for word in text.split(' '):\n",
    "        if word not in dictionary:\n",
    "            dictionary[word] = 0\n",
    "        dictionary[word] += 1\n",
    "    for word in dictionary:\n",
    "        p = dictionary[word] / count_words\n",
    "        dictionary[word] = -1 * p * math.log(p + eps)\n",
    "    sorted_dictionary = sorted(dictionary.items(), key=operator.itemgetter(1))[::-1]\n",
    "    answer = [x[0] for x in sorted_dictionary[:n]]\n",
    "    return answer\n",
    "\n",
    "def get_min_entropy_words(text, n):\n",
    "    '''\n",
    "    :param text: input text in russian\n",
    "    :param n: number of most words with minimum entropy\n",
    "    :return: list of words with entropies\n",
    "    '''\n",
    "    dictionary = {}\n",
    "    count_words = len(text.split(' '))\n",
    "    eps = 1e-7\n",
    "    for word in text.split(' '):\n",
    "        if word not in dictionary:\n",
    "            dictionary[word] = 0\n",
    "        dictionary[word] += 1\n",
    "    for word in dictionary:\n",
    "        p = dictionary[word] / count_words\n",
    "        dictionary[word] = -1 * p * math.log(p + eps)\n",
    "    sorted_dictionary = sorted(dictionary.items(), key=operator.itemgetter(1))\n",
    "    answer = [x[0] for x in sorted_dictionary[:n]]\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '4']\n",
      "['1', '4']\n",
      "['5', '6']\n"
     ]
    }
   ],
   "source": [
    "text = '1 2 1 2 1 4 5 6 4 1 8'\n",
    "print(get_top_words(text, 2))\n",
    "print(get_max_entropy_words(text, 2))\n",
    "print(get_min_entropy_words(text, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Pymorphy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymorphy2\n",
      "  Downloading https://files.pythonhosted.org/packages/a3/33/fff9675c68b5f6c63ec8c6e6ff57827dda28a1fa5b2c2d727dffff92dd47/pymorphy2-0.8-py2.py3-none-any.whl (46kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 609kB/s ta 0:00:01\n",
      "\u001b[?25hCollecting pymorphy2-dicts<3.0,>=2.4 (from pymorphy2)\n",
      "  Downloading https://files.pythonhosted.org/packages/02/51/2465fd4f72328ab50877b54777764d928da8cb15b74e2680fc1bd8cb3173/pymorphy2_dicts-2.4.393442.3710985-py2.py3-none-any.whl (7.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 7.1MB 98kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting docopt>=0.6 (from pymorphy2)\n",
      "  Downloading https://files.pythonhosted.org/packages/a2/55/8f8cab2afd404cf578136ef2cc5dfb50baa1761b68c9da1fb1e4eed343c9/docopt-0.6.2.tar.gz\n",
      "Collecting dawg-python>=0.7 (from pymorphy2)\n",
      "  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n",
      "Building wheels for collected packages: docopt\n",
      "  Running setup.py bdist_wheel for docopt ... \u001b[?25lerror\n",
      "  Complete output from command /home/egorov/NLP/env/bin/python3 -u -c \"import setuptools, tokenize;__file__='/tmp/pip-build-lu5vtd1w/docopt/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" bdist_wheel -d /tmp/tmpfbzga56rpip-wheel- --python-tag cp36:\n",
      "  usage: -c [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...]\n",
      "     or: -c --help [cmd1 cmd2 ...]\n",
      "     or: -c --help-commands\n",
      "     or: -c cmd --help\n",
      "  \n",
      "  error: invalid command 'bdist_wheel'\n",
      "  \n",
      "  ----------------------------------------\n",
      "\u001b[31m  Failed building wheel for docopt\u001b[0m\n",
      "\u001b[?25h  Running setup.py clean for docopt\n",
      "Failed to build docopt\n",
      "Installing collected packages: pymorphy2-dicts, docopt, dawg-python, pymorphy2\n",
      "  Running setup.py install for docopt ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed dawg-python-0.7.2 docopt-0.6.2 pymorphy2-0.8 pymorphy2-dicts-2.4.393442.3710985\n",
      "Collecting pymorphy2-dicts-ru\n",
      "  Downloading https://files.pythonhosted.org/packages/7c/9b/358faaff410f65a4ad159275e897b5956dcb20576c5b8e764b971c1634d7/pymorphy2_dicts_ru-2.4.404381.4453942-py2.py3-none-any.whl (8.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 8.0MB 88kB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pymorphy2-dicts-ru\n",
      "Successfully installed pymorphy2-dicts-ru-2.4.404381.4453942\n"
     ]
    }
   ],
   "source": [
    "# установка модуля и словарей\n",
    "!pip install pymorphy2\n",
    "!pip install -U pymorphy2-dicts-ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создание анализатора\n",
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_text = u'Глокая куздра штеко будланула бокра и кудрячит бокренка'\n",
    "# в отличие от mystem работает пословно\n",
    "pymorphy_results = map(lambda x: morph.parse(x), sample_text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "гло́кая\n",
      "\t гло́кай NOUN,anim,masc,Name sing,gent 0.3333423559982676\n",
      "\t гло́кай NOUN,anim,masc,Name sing,accs 0.3333423559982676\n",
      "\t гло́кий ADJF femn,sing,nomn 0.3083315288003464\n",
      "\t гло́кий NOUN,anim,femn,Sgtm,Surn sing,nomn 0.021410783889129488\n",
      "\t гло́кать GRND,impf,intr pres 0.0035729753139887395\n",
      "ку́здра\n",
      "\t ку́здра NOUN,inan,femn,Sgtm,Fixd,Abbr,Geox sing,nomn 0.15000000000000002\n",
      "\t ку́здра NOUN,inan,femn,Sgtm,Fixd,Abbr,Geox sing,gent 0.15000000000000002\n",
      "\t ку́здра NOUN,inan,femn,Sgtm,Fixd,Abbr,Geox sing,datv 0.15000000000000002\n",
      "\t ку́здра NOUN,inan,femn,Sgtm,Fixd,Abbr,Geox sing,accs 0.15000000000000002\n",
      "\t ку́здра NOUN,inan,femn,Sgtm,Fixd,Abbr,Geox sing,ablt 0.15000000000000002\n",
      "\t ку́здра NOUN,inan,femn,Sgtm,Fixd,Abbr,Geox sing,loct 0.15000000000000002\n",
      "\t ку́здра NOUN,inan,femn,Sgtm sing,nomn 0.05\n",
      "\t ку́здра NOUN,inan,femn,Sgtm,Geox sing,nomn 0.05\n",
      "ште́ко\n",
      "\t ште́ко NOUN,anim,GNdr,Ms-f,Fixd,Surn sing,nomn 0.07995028997514501\n",
      "\t ште́ко NOUN,anim,GNdr,Ms-f,Fixd,Surn sing,gent 0.07995028997514501\n",
      "\t ште́ко NOUN,anim,GNdr,Ms-f,Fixd,Surn sing,datv 0.07995028997514501\n",
      "\t ште́ко NOUN,anim,GNdr,Ms-f,Fixd,Surn sing,accs 0.07995028997514501\n",
      "\t ште́ко NOUN,anim,GNdr,Ms-f,Fixd,Surn sing,ablt 0.07995028997514501\n",
      "\t ште́ко NOUN,anim,GNdr,Ms-f,Fixd,Surn sing,loct 0.07995028997514501\n",
      "\t ште́ко NOUN,anim,GNdr,Ms-f,Fixd,Surn plur,nomn 0.07995028997514501\n",
      "\t ште́ко NOUN,anim,GNdr,Ms-f,Fixd,Surn plur,gent 0.07995028997514501\n",
      "\t ште́ко NOUN,anim,GNdr,Ms-f,Fixd,Surn plur,datv 0.07995028997514501\n",
      "\t ште́ко NOUN,anim,GNdr,Ms-f,Fixd,Surn plur,accs 0.07995028997514501\n",
      "\t ште́ко NOUN,anim,GNdr,Ms-f,Fixd,Surn plur,ablt 0.07995028997514501\n",
      "\t ште́ко NOUN,anim,GNdr,Ms-f,Fixd,Surn plur,loct 0.07995028997514501\n",
      "\t ште́ко ADVB 0.019469759734879875\n",
      "\t ште́кий ADJS neut,sing 0.007870753935376971\n",
      "\t ште́ко ADJF,Fixd,Subx,Qual masc,sing,nomn 0.0005523336095001382\n",
      "\t ште́ко ADJF,Fixd,Subx,Qual masc,sing,gent 0.0005523336095001382\n",
      "\t ште́ко ADJF,Fixd,Subx,Qual masc,sing,datv 0.0005523336095001382\n",
      "\t ште́ко ADJF,Fixd,Subx,Qual masc,sing,accs 0.0005523336095001382\n",
      "\t ште́ко ADJF,Fixd,Subx,Qual masc,sing,ablt 0.0005523336095001382\n",
      "\t ште́ко ADJF,Fixd,Subx,Qual masc,sing,loct 0.0005523336095001382\n",
      "\t ште́ко ADJF,Fixd,Subx,Qual femn,sing,nomn 0.0005523336095001382\n",
      "\t ште́ко ADJF,Fixd,Subx,Qual femn,sing,gent 0.0005523336095001382\n",
      "\t ште́ко ADJF,Fixd,Subx,Qual femn,sing,datv 0.0005523336095001382\n",
      "\t ште́ко ADJF,Fixd,Subx,Qual femn,sing,accs 0.0005523336095001382\n",
      "\t ште́ко ADJF,Fixd,Subx,Qual femn,sing,ablt 0.0005523336095001382\n",
      "\t ште́ко ADJF,Fixd,Subx,Qual femn,sing,loct 0.0005523336095001382\n",
      "\t ште́ко ADJF,Fixd,Subx,Qual neut,sing,nomn 0.0005523336095001382\n",
      "\t ште́ко ADJF,Fixd,Subx,Qual neut,sing,gent 0.0005523336095001382\n",
      "\t ште́ко ADJF,Fixd,Subx,Qual neut,sing,datv 0.0005523336095001382\n",
      "\t ште́ко ADJF,Fixd,Subx,Qual neut,sing,accs 0.0005523336095001382\n",
      "\t ште́ко ADJF,Fixd,Subx,Qual neut,sing,ablt 0.0005523336095001382\n",
      "\t ште́ко ADJF,Fixd,Subx,Qual neut,sing,loct 0.0005523336095001382\n",
      "\t ште́ко ADJF,Fixd,Subx,Qual plur,nomn 0.0005523336095001382\n",
      "\t ште́ко ADJF,Fixd,Subx,Qual plur,gent 0.0005523336095001382\n",
      "\t ште́ко ADJF,Fixd,Subx,Qual plur,datv 0.0005523336095001382\n",
      "\t ште́ко ADJF,Fixd,Subx,Qual plur,accs 0.0005523336095001382\n",
      "\t ште́ко ADJF,Fixd,Subx,Qual plur,ablt 0.0005523336095001382\n",
      "\t ште́ко ADJF,Fixd,Subx,Qual plur,loct 0.0005523336095001382\n",
      "будлану́ла\n",
      "\t будлану́ть VERB,impf,tran femn,sing,past,indc 0.8499077645480463\n",
      "\t будлану́л NOUN,inan,masc sing,gent 0.11235955056179775\n",
      "\t будлану́лый ADJS femn,sing 0.03622337749454972\n",
      "\t будлану́ла ADVB 0.0015093073956062384\n",
      "бо́кра\n",
      "\t бо́кр NOUN,inan,masc sing,gent 0.4444444444444445\n",
      "\t бо́кра NOUN,inan,femn sing,nomn 0.4444444444444445\n",
      "\t бо́крый ADJS,Qual femn,sing 0.11111111111111112\n",
      "и\n",
      "\t и CONJ 0.997671\n",
      "\t и INTJ 0.000436\n",
      "\t и PRCL 0.000145\n",
      "\t исполняющий NOUN,anim,masc,Fixd,Abbr sing,nomn 0.000145\n",
      "\t исполняющий NOUN,anim,masc,Fixd,Abbr sing,gent 0.000145\n",
      "\t исполняющий NOUN,anim,masc,Fixd,Abbr sing,datv 0.000145\n",
      "\t исполняющий NOUN,anim,masc,Fixd,Abbr sing,accs 0.000145\n",
      "\t исполняющий NOUN,anim,masc,Fixd,Abbr sing,ablt 0.000145\n",
      "\t исполняющий NOUN,anim,masc,Fixd,Abbr sing,loct 0.000145\n",
      "\t исполняющий NOUN,anim,masc,Fixd,Abbr plur,nomn 0.000145\n",
      "\t исполняющий NOUN,anim,masc,Fixd,Abbr plur,gent 0.000145\n",
      "\t исполняющий NOUN,anim,masc,Fixd,Abbr plur,datv 0.000145\n",
      "\t исполняющий NOUN,anim,masc,Fixd,Abbr plur,accs 0.000145\n",
      "\t исполняющий NOUN,anim,masc,Fixd,Abbr plur,ablt 0.000145\n",
      "\t исполняющий NOUN,anim,masc,Fixd,Abbr plur,loct 0.000145\n",
      "курдя́чит\n",
      "\t курдя́чить VERB,perf,tran sing,3per,futr,indc 0.9411764705882354\n",
      "\t курдя́читый ADJS,Qual masc,sing 0.007352941176470589\n",
      "\t курдя́чит NOUN,anim,femn,Sgtm,Fixd,Name sing,nomn 0.007352941176470589\n",
      "\t курдя́чит NOUN,anim,femn,Sgtm,Fixd,Name sing,gent 0.007352941176470589\n",
      "\t курдя́чит NOUN,anim,femn,Sgtm,Fixd,Name sing,datv 0.007352941176470589\n",
      "\t курдя́чит NOUN,anim,femn,Sgtm,Fixd,Name sing,accs 0.007352941176470589\n",
      "\t курдя́чит NOUN,anim,femn,Sgtm,Fixd,Name sing,ablt 0.007352941176470589\n",
      "\t курдя́чит NOUN,anim,femn,Sgtm,Fixd,Name sing,loct 0.007352941176470589\n",
      "\t курдя́читый ADJS masc,sing 0.007352941176470589\n",
      "бокрёнка\n",
      "\t бокрёнок NOUN,anim,masc sing,gent 0.49999999999999994\n",
      "\t бокрёнок NOUN,anim,masc sing,accs 0.49999999999999994\n"
     ]
    }
   ],
   "source": [
    "# собираем результаты и выводим \n",
    "for word_result in pymorphy_results:\n",
    "    print (word_result[0].word)\n",
    "    for res in word_result:\n",
    "#         print repr(res).decode('unicode_escape')\n",
    "        print ('\\t', res.normal_form, res.tag, res.score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В отличие от mystem можно получать лексему и склонять слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "градус NOUN,inan,masc sing,nomn\n",
      "градуса NOUN,inan,masc sing,gent\n",
      "градусу NOUN,inan,masc sing,datv\n",
      "градус NOUN,inan,masc sing,accs\n",
      "градусом NOUN,inan,masc sing,ablt\n",
      "градусе NOUN,inan,masc sing,loct\n",
      "градусы NOUN,inan,masc plur,nomn\n",
      "градусов NOUN,inan,masc plur,gent\n",
      "градусам NOUN,inan,masc plur,datv\n",
      "градусы NOUN,inan,masc plur,accs\n",
      "градусами NOUN,inan,masc plur,ablt\n",
      "градусах NOUN,inan,masc plur,loct\n"
     ]
    }
   ],
   "source": [
    "bokr = morph.parse(u'градус')[0]\n",
    "for form in bokr.lexeme:\n",
    "    print (form.word, form.tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "градусе\n",
      "градус\n",
      "градуса\n",
      "градусов\n"
     ]
    }
   ],
   "source": [
    "print (bokr.inflect({'loct'}).word,)\n",
    "print (bokr.make_agree_with_number(1).word,)\n",
    "print (bokr.make_agree_with_number(2).word,)\n",
    "print (bokr.make_agree_with_number(5).word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание \n",
    "С помощью pymorphy на тексте получить:\n",
    "- Распределение по частям речи\n",
    "- Для части речи вывести топ n лексем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos_distribution(text, lexemas=None):\n",
    "    '''\n",
    "    :param: text: input text in russian\n",
    "    :param: lexemas: list of interested pos, if None - all are interesting \n",
    "    :return: dict of pos - probability\n",
    "    '''\n",
    "    pos = {}\n",
    "    count_words = len(text.split(' '))\n",
    "    for word in text.split(' '):\n",
    "        bokr = morph.parse(word)[0]\n",
    "        pos_word = bokr.tag.POS\n",
    "        if pos_word not in pos:\n",
    "            pos[pos_word] = 0\n",
    "        pos[pos_word] += 1\n",
    "    for pos_key in pos:\n",
    "        pos[pos_key] = float(pos[pos_key]) / count_words\n",
    "    if lexemas is None:\n",
    "        return pos\n",
    "    answer = {}\n",
    "    for lexem in lexemas:\n",
    "        answer[lexem] = pos[lexem]\n",
    "    return answer\n",
    "\n",
    "def get_top_pos_words(text, pos, n):\n",
    "    '''\n",
    "    :param text: input text in russian\n",
    "    :param pos: part of speech \n",
    "    :param n: number of most common words\n",
    "    :return: list of most common lexemas with selected pos\n",
    "    '''\n",
    "    words = {}\n",
    "    count_words = len(text.split(' '))\n",
    "    for word in text.split(' '):\n",
    "        bokr = morph.parse(word)[0]\n",
    "        pos_word = bokr.tag.POS\n",
    "        if pos_word == pos:\n",
    "            if word not in words:\n",
    "                words[word] = 0\n",
    "            words[word] += 1\n",
    "    sorted_dictionary = sorted(words.items(), key=operator.itemgetter(1))[::-1]\n",
    "    answer = sorted_dictionary[:n]\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Гло́кая ку́здра ште́ко будлану́ла бо́кра и курдя́чит бокрёнка\n",
      "{'NOUN': 0.625, 'VERB': 0.25, 'CONJ': 0.125}\n",
      "[('бокрёнка', 1)]\n"
     ]
    }
   ],
   "source": [
    "print(sample_text)\n",
    "print(get_pos_distribution(sample_text))\n",
    "print(get_top_pos_words(sample_text, u'NOUN', 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
